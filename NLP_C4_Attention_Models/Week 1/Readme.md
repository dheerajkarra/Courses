# Week 1 - Neural Machine Translation 

Discover some of the shortcomings of a traditional seq2seq model and how to solve for them by adding an attention mechanism, then build a Neural Machine Translation model with Attention that translates English sentences into German.

## Learning Objectives

* Explain how an Encoder/Decoder model works
* Apply word alignment for machine translation
* Develop intuition for how teacher forcing helps a translation model check its predictions
* Use BLEU score and ROUGE score to evaluate machine-generated text quality
* Describe several decoding methods including MBR and Beam search

### Assignment
Translate English sentence to Portugese sentence using attention mechanism.
